{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Evaluation of VLM Responses (Only for GPT Judge) ~ For Our Manuscript we had Agriculture Experts Analyze the Results\n",
        "\n",
        "**Metrics**\n",
        "- **Weed Detection Accuracy**: Strict Yes/No match between `Weed Detection (Prediction)` and `Weed Detection (GT)`.\n",
        "- **Crop Growth Accuracy (Adjacent)**: treats growth as an ordered scale and counts predictions within **1 step** as correct.\n",
        "- **Crop Type Fuzzy-Accuracy @ 80%**: similarity between `Crop Type (Prediction)` and `Crop Type (GT)` using difflib; counts as correct if similarity ≥ 0.80 (after normalization).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                 sheet  weed_detection_accuracy  weed_n  crop_growth_accuracy  growth_n  crop_type_accuracy  crop_type_n\n",
            "      Gemini_Flash_2.5                 0.772834     427                   NaN         0            0.884793          434\n",
            " Gemini_Flash_Lite_2.5                 0.682540     441                   NaN         0            0.895692          441\n",
            "      LLaMA_4_Maverick                 0.455782     441                   NaN         0            0.482993          441\n",
            "         LLaMA_4_Scout                 0.149660     441                   NaN         0            0.000000          441\n",
            "           ChatGPT_4.1                 0.308390     441                   NaN         0            0.589569          441\n",
            "            ChatGPT_4o                 0.455172     435                   NaN         0            0.671264          435\n",
            "          Weed_Dataset                      NaN       0                   NaN         0            0.000000            1\n",
            "LLaMA_4_Maverick (Old)                 0.455782     441                   NaN         0            0.403628          441\n",
            "           __OVERALL__                 0.467232    3067                   NaN         0            0.560000         3075\n"
          ]
        }
      ],
      "source": [
        "# Inline-only evaluation (no files written)\n",
        "import os, re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from difflib import SequenceMatcher\n",
        "\n",
        "# ================== CONFIG ==================\n",
        "excel_path = \"/Complete_Weed_VLM_Evaluation(REFINED).xlsx\"\n",
        "\n",
        "# Column names\n",
        "COL_WEED_GT   = \"Weed Detection (GT)\"\n",
        "COL_WEED_PRED = \"Weed Detection (Prediction)\"\n",
        "COL_GROWTH_PRED = \"Crop Growth (Prediction)\"\n",
        "COL_RESPONSE  = \"GPT_Response\"\n",
        "COL_CROP_GT   = \"Crop Type (GT)\"\n",
        "COL_CROP_PRED = \"Crop Type (Prediction)\"\n",
        "\n",
        "# Growth normalization\n",
        "GROWTH_ORDER = [\"seedling\", \"young\", \"growing\", \"mature\", \"full grown\"]\n",
        "GROWTH_SYNONYMS = {\n",
        "    \"seed\": \"seedling\", \"sprout\": \"seedling\", \"seedling\": \"seedling\",\n",
        "    \"young\": \"young\", \"early\": \"young\",\n",
        "    \"growing\": \"growing\", \"growth\": \"growing\", \"mid\": \"growing\",\n",
        "    \"mature\": \"mature\", \"ripened\": \"mature\",\n",
        "    \"full grown\": \"full grown\", \"full-grown\": \"full grown\",\n",
        "    \"fully grown\": \"full grown\", \"harvest-ready\": \"full grown\", \"harvest ready\": \"full grown\",\n",
        "}\n",
        "\n",
        "def to_str(x):\n",
        "    if pd.isna(x): return \"\"\n",
        "    return str(x).strip()\n",
        "\n",
        "def normalize_yes_no(x):\n",
        "    s = re.sub(r'[^a-z]', '', to_str(x).lower())\n",
        "    if s in {\"yes\",\"y\",\"true\"}: return 1\n",
        "    if s in {\"no\",\"n\",\"false\"}: return 0\n",
        "    return None\n",
        "\n",
        "def normalize_growth(x):\n",
        "    s = to_str(x).lower()\n",
        "    s = re.sub(r'\\s+', ' ', s).replace(\"_\",\" \").replace(\"-\",\" \").strip()\n",
        "    if not s: return None\n",
        "    if s in GROWTH_ORDER: return s\n",
        "    toks = s.split()\n",
        "    if \"full\" in toks and \"grown\" in toks: return \"full grown\"\n",
        "    for t in toks:\n",
        "        if t in GROWTH_SYNONYMS: return GROWTH_SYNONYMS[t]\n",
        "    # fuzzy fallback to nearest label\n",
        "    best,score=-1,None\n",
        "    for i,g in enumerate(GROWTH_ORDER):\n",
        "        r = SequenceMatcher(None, s, g).ratio()\n",
        "        if score is None or r>score:\n",
        "            score=r; best=g\n",
        "    return best\n",
        "\n",
        "def normalize_crop_type(x):\n",
        "    s = to_str(x).lower()\n",
        "    s = re.sub(r'[^a-z0-9\\s/+-]', '', s)\n",
        "    s = re.sub(r'\\s+',' ', s).strip()\n",
        "    if not s: return \"\"\n",
        "    if s.endswith('ies'): s = s[:-3] + 'y'\n",
        "    elif s.endswith('ses'): s = s[:-2]\n",
        "    elif s.endswith('s') and not s.endswith('ss'): s = s[:-1]\n",
        "    aliases = {\"soybean\":\"soybean\",\"soy\":\"soybean\",\"soyabean\":\"soybean\",\"maize\":\"corn\",\n",
        "               \"corn\":\"corn\",\"wheat\":\"wheat\",\"barley\":\"barley\",\"rice\":\"rice\",\"unknown\":\"unknown\"}\n",
        "    return aliases.get(s, s)\n",
        "\n",
        "def extract_from_response(text, field):\n",
        "    \"\"\"\n",
        "    Extract value like 'Crop Growth: Growing' from Gemini_Response free text.\n",
        "    field examples: 'Crop Growth', 'Crop Type'.\n",
        "    \"\"\"\n",
        "    s = to_str(text)\n",
        "    # capture until line break or sentence end\n",
        "    pat = rf'(?is){re.escape(field)}\\s*:\\s*([A-Za-z \\-_/]+?)($|\\n|\\r|\\.|,)'  # non-greedy\n",
        "    m = re.search(pat, s)\n",
        "    if m: return m.group(1).strip()\n",
        "    return \"\"\n",
        "\n",
        "def safe_acc(matches):\n",
        "    if not matches: return float('nan')\n",
        "    return float(sum(matches) / len(matches))\n",
        "\n",
        "def evaluate_sheet(df, sheet):\n",
        "    # 1) Weed Detection: Prediction vs GT\n",
        "    wd_matches = []\n",
        "    if COL_WEED_GT in df.columns and COL_WEED_PRED in df.columns:\n",
        "        for _, row in df[[COL_WEED_GT, COL_WEED_PRED]].iterrows():\n",
        "            g = normalize_yes_no(row[COL_WEED_GT])\n",
        "            p = normalize_yes_no(row[COL_WEED_PRED])\n",
        "            if g is None or p is None: continue\n",
        "            wd_matches.append(g==p)\n",
        "    weed_acc = safe_acc(wd_matches); n_wd=len(wd_matches)\n",
        "\n",
        "    # 2) Crop Growth: Prediction vs Response (parsed)\n",
        "    cg_matches = []\n",
        "    if COL_GROWTH_PRED in df.columns and COL_RESPONSE in df.columns:\n",
        "        for _, row in df[[COL_GROWTH_PRED, COL_RESPONSE]].iterrows():\n",
        "            pred = normalize_growth(row[COL_GROWTH_PRED])\n",
        "            resp_raw = extract_from_response(row[COL_RESPONSE], \"Crop Growth\")\n",
        "            resp = normalize_growth(resp_raw)\n",
        "            if pred is None or resp is None: continue\n",
        "            cg_matches.append(pred==resp)\n",
        "    cg_acc = safe_acc(cg_matches); n_cg=len(cg_matches)\n",
        "\n",
        "    # 3) Crop Type: Prediction vs GT (strict, normalized)\n",
        "    ct_matches = []\n",
        "    if COL_CROP_GT in df.columns and COL_CROP_PRED in df.columns:\n",
        "        for _, row in df[[COL_CROP_GT, COL_CROP_PRED]].iterrows():\n",
        "            g = normalize_crop_type(row[COL_CROP_GT])\n",
        "            p = normalize_crop_type(row[COL_CROP_PRED])\n",
        "            if not g or not p: continue\n",
        "            ct_matches.append(g==p)\n",
        "    ct_acc = safe_acc(ct_matches); n_ct=len(ct_matches)\n",
        "\n",
        "    return {\n",
        "        \"sheet\": sheet,\n",
        "        \"weed_detection_accuracy\": weed_acc, \"weed_n\": n_wd,\n",
        "        \"crop_growth_accuracy\": cg_acc, \"growth_n\": n_cg,\n",
        "        \"crop_type_accuracy\": ct_acc, \"crop_type_n\": n_ct,\n",
        "    }\n",
        "\n",
        "def evaluate_workbook(path):\n",
        "    xl = pd.ExcelFile(path)\n",
        "    res = []\n",
        "    for name in xl.sheet_names:\n",
        "        df = xl.parse(name)\n",
        "        res.append(evaluate_sheet(df, name))\n",
        "    summary = pd.DataFrame(res)\n",
        "\n",
        "    # weighted overall by valid counts\n",
        "    def wavg(col_acc, col_n):\n",
        "        w = summary[col_n].fillna(0).astype(float)\n",
        "        a = summary[col_acc].fillna(0).astype(float)\n",
        "        d = w.sum()\n",
        "        if d==0: return float('nan')\n",
        "        return float((w*a).sum()/d)\n",
        "\n",
        "    overall = {\n",
        "        \"sheet\": \"__OVERALL__\",\n",
        "        \"weed_detection_accuracy\": wavg(\"weed_detection_accuracy\",\"weed_n\"),\n",
        "        \"weed_n\": int(summary[\"weed_n\"].sum() if \"weed_n\" in summary else 0),\n",
        "        \"crop_growth_accuracy\": wavg(\"crop_growth_accuracy\",\"growth_n\"),\n",
        "        \"growth_n\": int(summary[\"growth_n\"].sum() if \"growth_n\" in summary else 0),\n",
        "        \"crop_type_accuracy\": wavg(\"crop_type_accuracy\",\"crop_type_n\"),\n",
        "        \"crop_type_n\": int(summary[\"crop_type_n\"].sum() if \"crop_type_n\" in summary else 0),\n",
        "    }\n",
        "    full = pd.concat([summary, pd.DataFrame([overall])], ignore_index=True)\n",
        "    return full\n",
        "\n",
        "if not os.path.exists(excel_path):\n",
        "    print(\"⚠️ Excel file not found at:\", excel_path)\n",
        "    print(\"Upload your workbook to /mnt/data and set excel_path accordingly.\")\n",
        "else:\n",
        "    df_out = evaluate_workbook(excel_path)\n",
        "    try:\n",
        "        from caas_jupyter_tools import display_dataframe_to_user\n",
        "        display_dataframe_to_user(\"Inline Evaluation Summary\", df_out)\n",
        "    except Exception:\n",
        "        pass\n",
        "    print(df_out.to_string(index=False))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2a4758f3",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating sheet: Gemini_Flash_Lite_2.5 (rows: 450)\n",
            "Weed Detection Accuracy: 0.6847 (n=444)\n",
            "Crop Growth Accuracy (Early/Growing/Full Grown): 0.0000 (n=440)\n",
            "Crop Type Accuracy (strict): 0.9048 (n=441)\n"
          ]
        }
      ],
      "source": [
        "# ---- Configuration & Sheet Listing ----\n",
        "import pandas as pd, os\n",
        "\n",
        "# Set your Excel path here\n",
        "\n",
        "excel_path = r\"/Comprehensive_WeedVLM.xlsx\"\n",
        "\n",
        "# if not os.path.exists(excel_path):\n",
        "#     print(\"⚠️ Excel file not found at:\", excel_path)\n",
        "# else:\n",
        "#     xl = pd.ExcelFile(excel_path)\n",
        "#     print(\"Found sheets:\")\n",
        "#     for i, name in enumerate(xl.sheet_names, start=1):\n",
        "#         print(f\"{i}. {name}\")\n",
        "\n",
        "# ---- Single-Sheet Evaluation ----\n",
        "import os, re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Columns\n",
        "COL_WEED_GT     = \"Weed Detection (GT)\"\n",
        "COL_WEED_PRED   = \"Weed Detection (Prediction)\"\n",
        "COL_GROWTH_GT   = \"Crop Growth (GT)\"\n",
        "COL_GROWTH_PRED = \"Crop Growth (Prediction)\"\n",
        "COL_CROP_GT     = \"Crop Type (GT)\"\n",
        "COL_CROP_PRED   = \"Crop Type (Prediction)\"\n",
        "\n",
        "# Choose ONE of these (name has priority if both set)\n",
        "SHEET_NAME  = \"Gemini_Flash_Lite_2.5\"  # e.g., \"Gemini_Flash_Lite_2.5\", \"LLaMA_4_Maverick\", \"LLaMA_4_Scout\", \"ChatGPT_4.1\", \"ChatGPT_4o\"\n",
        "SHEET_INDEX = None          # 1-based index, e.g., 2 for the second sheet\n",
        "\n",
        "# ----- Normalizers -----\n",
        "def to_str(x):\n",
        "    if pd.isna(x): return \"\"\n",
        "    return str(x).strip()\n",
        "\n",
        "def norm_weed_label(x):\n",
        "    \"\"\"Return one of: 'yes', 'no', 'n/a', '' (empty).\"\"\"\n",
        "    s_raw = to_str(x).lower()\n",
        "    if s_raw == \"\":\n",
        "        return \"\"\n",
        "    letters = re.sub(r'[^a-z]', '', s_raw)  # drop spaces, punctuation\n",
        "    if letters == \"yes\": return \"yes\"\n",
        "    if letters == \"no\":  return \"no\"\n",
        "    if letters == \"na\":  return \"n/a\"\n",
        "    return s_raw.strip()\n",
        "\n",
        "def norm_growth(x):\n",
        "    \"\"\"Map to one of: 'early', 'growing', 'full grown'.\"\"\"\n",
        "    s = to_str(x).lower()\n",
        "    s = re.sub(r'[\\s_-]+', ' ', s).strip()\n",
        "    if not s: return None\n",
        "    if s in {\"early\"}: return \"early\"\n",
        "    if s in {\"growing\"}: return \"growing\"\n",
        "    if s in {\"full grown\", \"full-grown\", \"fully grown\"}: return \"full grown\"\n",
        "    if \"full\" in s and \"grown\" in s: return \"full grown\"\n",
        "    return s\n",
        "\n",
        "def norm_crop_type(x):\n",
        "    \"\"\"Strict, minimal normalization: case-insensitive + trim only.\"\"\"\n",
        "    return to_str(x).strip().lower()\n",
        "\n",
        "def safe_acc(matches):\n",
        "    if not matches: return float('nan')\n",
        "    return float(sum(matches) / len(matches))\n",
        "\n",
        "# ----- Load sheet -----\n",
        "if not os.path.exists(excel_path):\n",
        "    print(\"⚠️ Excel file not found at:\", excel_path)\n",
        "else:\n",
        "    xl = pd.ExcelFile(excel_path)\n",
        "    sheet_to_use = None\n",
        "    if SHEET_NAME is not None and SHEET_NAME in xl.sheet_names:\n",
        "        sheet_to_use = SHEET_NAME\n",
        "    elif SHEET_INDEX is not None:\n",
        "        try:\n",
        "            idx0 = int(SHEET_INDEX) - 1\n",
        "            if 0 <= idx0 < len(xl.sheet_names):\n",
        "                sheet_to_use = xl.sheet_names[idx0]\n",
        "        except Exception:\n",
        "            sheet_to_use = None\n",
        "    else:\n",
        "        # default to first sheet if neither provided\n",
        "        if len(xl.sheet_names) > 0:\n",
        "            sheet_to_use = xl.sheet_names[0]\n",
        "\n",
        "    if sheet_to_use is None:\n",
        "        print(\"⚠️ Please set SHEET_NAME (exact) or SHEET_INDEX (1-based) to a valid sheet.\")\n",
        "    else:\n",
        "        df = xl.parse(sheet_to_use)\n",
        "        print(f\"Evaluating sheet: {sheet_to_use} (rows: {len(df)})\")\n",
        "\n",
        "        # 1) Weed Detection accuracy\n",
        "        wd_matches = []\n",
        "        if COL_WEED_GT in df.columns and COL_WEED_PRED in df.columns:\n",
        "            for _, row in df[[COL_WEED_GT, COL_WEED_PRED]].iterrows():\n",
        "                gt = norm_weed_label(row[COL_WEED_GT])\n",
        "                pr = norm_weed_label(row[COL_WEED_PRED])\n",
        "                if gt in {\"yes\",\"no\",\"n/a\",\"\"} and pr in {\"yes\",\"no\",\"n/a\",\"\"}:\n",
        "                    wd_matches.append(gt == pr)\n",
        "        wd_acc = safe_acc(wd_matches)\n",
        "        print(f\"Weed Detection Accuracy: {wd_acc:.4f} (n={len(wd_matches)})\")\n",
        "\n",
        "        # 2) Crop Growth accuracy (Prediction vs GT; classes: Early, Growing, Full Grown)\n",
        "        cg_matches = []\n",
        "        if COL_GROWTH_GT in df.columns and COL_GROWTH_PRED in df.columns:\n",
        "            for _, row in df[[COL_GROWTH_GT, COL_GROWTH_PRED]].iterrows():\n",
        "                gt = norm_growth(row[COL_GROWTH_GT])\n",
        "                pr = norm_growth(row[COL_GROWTH_PRED])\n",
        "                if gt in {\"early\",\"growing\",\"full grown\"} and pr in {\"early\",\"growing\",\"full grown\"}:\n",
        "                    cg_matches.append(gt == pr)\n",
        "        cg_acc = safe_acc(cg_matches)\n",
        "        print(f\"Crop Growth Accuracy (Early/Growing/Full Grown): {cg_acc:.4f} (n={len(cg_matches)})\")\n",
        "\n",
        "        # 3) Crop Type accuracy (strict; no synonym/plural logic)\n",
        "        ct_matches = []\n",
        "        if COL_CROP_GT in df.columns and COL_CROP_PRED in df.columns:\n",
        "            for _, row in df[[COL_CROP_GT, COL_CROP_PRED]].iterrows():\n",
        "                gt = norm_crop_type(row[COL_CROP_GT])\n",
        "                pr = norm_crop_type(row[COL_CROP_PRED])\n",
        "                if gt != \"\" and pr != \"\":\n",
        "                    ct_matches.append(gt == pr)\n",
        "        ct_acc = safe_acc(ct_matches)\n",
        "        print(f\"Crop Type Accuracy (strict): {ct_acc:.4f} (n={len(ct_matches)})\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "470bbb45",
      "metadata": {},
      "source": [
        "## Refined Evaluation Code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "faf2f927",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating sheet: ChatGPT_4.1 (rows: 442)\n",
            "\n",
            ">>>>> Original Prompt Response <<<<<<\n",
            "Weed Detection Accuracy: 0.3100 (n=442)\n",
            "Crop Growth Accuracy: 0.1927 (n=441)\n",
            "Crop Type Accuracy: 0.5896 (n=441)\n",
            "\n",
            ">>>>> EPP Response <<<<<<\n",
            "EPP Accuracy (GT Weed Detection (GT) vs Pred V2_Weed Detection (Prediction)): 0.6923 (n=442)\n",
            "EPP Crop Growth Accuracy (GT Crop Growth (GT) vs Pred V2_Crop Growth (Prediction)): 0.1541 (n=305)\n",
            "EPP Crop Type Accuracy (GT Crop Type (GT) vs Pred V2_Crop Type (Prediction)): 0.6262 (n=305)\n"
          ]
        }
      ],
      "source": [
        "# ---- Single-Sheet Evaluation with Row Limits & EPP Metrics ----\n",
        "import os, re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Set Excel path\n",
        "excel_path = r\"/Complete_Weed_VLM_Evaluation(REFINED).xlsx\"\n",
        "\n",
        "# Columns (by header)\n",
        "COL_WEED_GT     = \"Weed Detection (GT)\"\n",
        "COL_WEED_PRED   = \"Weed Detection (Prediction)\"\n",
        "COL_GROWTH_GT   = \"Crop Growth (GT)\"\n",
        "COL_GROWTH_PRED = \"Crop Growth (Prediction)\"\n",
        "COL_CROP_GT     = \"Crop Type (GT)\"\n",
        "COL_CROP_PRED   = \"Crop Type (Prediction)\"\n",
        "\n",
        "# Choose ONE of these (name has priority if both set)\n",
        "SHEET_NAME  = \"ChatGPT_4.1\"  # e.g., \"Gemini_Flash_2.5\", \"Gemini_Flash_Lite_2.5\", \"LLaMA_4_Maverick\", \"LLaMA_4_Scout\", \"ChatGPT_4.1\", \"ChatGPT_4o\"\n",
        "SHEET_INDEX = None             # 1-based index (default: first sheet)\n",
        "\n",
        "# Optional row limits (inclusive, 1-based)\n",
        "DATA_ROW_START = 1\n",
        "DATA_ROW_END   = 442\n",
        "\n",
        "# ----- Normalizers -----\n",
        "def to_str(x):\n",
        "    if pd.isna(x): return \"\"\n",
        "    return str(x).strip()\n",
        "\n",
        "def norm_weed_label(x):\n",
        "    \"\"\"Return one of: 'yes', 'no', 'n/a', '' (empty).\"\"\"\n",
        "    s_raw = to_str(x).lower()\n",
        "    if s_raw == \"\": return \"\"\n",
        "    letters = re.sub(r'[^a-z]', '', s_raw)\n",
        "    if letters == \"yes\": return \"yes\"\n",
        "    if letters == \"no\":  return \"no\"\n",
        "    if letters == \"na\":  return \"n/a\"\n",
        "    return s_raw.strip()\n",
        "\n",
        "def norm_growth(x):\n",
        "    \"\"\"Map to one of: 'early', 'growing', 'full grown'.\"\"\"\n",
        "    s = to_str(x).lower()\n",
        "    s = re.sub(r'[\\s_-]+', ' ', s).strip()\n",
        "    if not s: return None\n",
        "    if s == \"early\": return \"early\"\n",
        "    if s == \"growing\": return \"growing\"\n",
        "    if s in {\"full grown\",\"full-grown\",\"fully grown\"}: return \"full grown\"\n",
        "    if \"full\" in s and \"grown\" in s: return \"full grown\"\n",
        "    return s\n",
        "\n",
        "def norm_crop_type(x):\n",
        "    \"\"\"Strict compare: case-insensitive + trim only.\"\"\"\n",
        "    return to_str(x).lower()\n",
        "\n",
        "def safe_acc(matches):\n",
        "    if not matches: return float('nan')\n",
        "    return float(sum(matches) / len(matches))\n",
        "\n",
        "def excel_col_to_index(col_letters: str) -> int:\n",
        "    \"\"\"Convert Excel col letters (e.g., 'A') to 0-based index.\"\"\"\n",
        "    col = col_letters.strip().upper()\n",
        "    total = 0\n",
        "    for ch in col:\n",
        "        total = total * 26 + (ord(ch) - ord('A') + 1)\n",
        "    return total - 1\n",
        "\n",
        "def series_by_col_letter(df: pd.DataFrame, col_letters: str):\n",
        "    idx = excel_col_to_index(col_letters)\n",
        "    if idx < 0 or idx >= df.shape[1]:\n",
        "        return None, None\n",
        "    return df.iloc[:, idx], df.columns[idx]\n",
        "\n",
        "def apply_row_limits(df: pd.DataFrame):\n",
        "    if DATA_ROW_START is None and DATA_ROW_END is None:\n",
        "        return df.copy()\n",
        "    start0 = max(0, DATA_ROW_START-1)\n",
        "    end0   = min(len(df), DATA_ROW_END)\n",
        "    return df.iloc[start0:end0].copy()\n",
        "\n",
        "def accuracy_from_series(gt_ser, pr_ser, normalizer, allowed=None):\n",
        "    matches = []\n",
        "    for gt, pr in zip(gt_ser, pr_ser):\n",
        "        g, p = normalizer(gt), normalizer(pr)\n",
        "        if allowed is not None:\n",
        "            if g not in allowed or p not in allowed: continue\n",
        "        else:\n",
        "            if g==\"\" or p==\"\": continue\n",
        "        matches.append(g==p)\n",
        "    return safe_acc(matches), len(matches)\n",
        "\n",
        "# ---- Run evaluation ----\n",
        "if not os.path.exists(excel_path):\n",
        "    print(\"⚠️ Excel file not found at:\", excel_path)\n",
        "else:\n",
        "    xl = pd.ExcelFile(excel_path)\n",
        "    sheet_to_use = SHEET_NAME or xl.sheet_names[SHEET_INDEX-1]\n",
        "    df_full = xl.parse(sheet_to_use)\n",
        "    df = apply_row_limits(df_full)\n",
        "    print(f\"Evaluating sheet: {sheet_to_use} (rows: {len(df)})\")\n",
        "\n",
        "    print(\"\\n>>>>> Original Prompt Response <<<<<<\")\n",
        "    # Core metrics\n",
        "    if COL_WEED_GT in df and COL_WEED_PRED in df:\n",
        "        wd_acc, wd_n = accuracy_from_series(df[COL_WEED_GT], df[COL_WEED_PRED],\n",
        "                                            norm_weed_label, {\"yes\",\"no\",\"n/a\",\"\"})\n",
        "        print(f\"Weed Detection Accuracy: {wd_acc:.4f} (n={wd_n})\")\n",
        "\n",
        "    if COL_GROWTH_GT in df and COL_GROWTH_PRED in df:\n",
        "        cg_acc, cg_n = accuracy_from_series(df[COL_GROWTH_GT], df[COL_GROWTH_PRED],\n",
        "                                            norm_growth, {\"early\",\"growing\",\"full grown\"})\n",
        "        print(f\"Crop Growth Accuracy: {cg_acc:.4f} (n={cg_n})\")\n",
        "\n",
        "    if COL_CROP_GT in df and COL_CROP_PRED in df:\n",
        "        ct_acc, ct_n = accuracy_from_series(df[COL_CROP_GT], df[COL_CROP_PRED],\n",
        "                                            norm_crop_type)\n",
        "        print(f\"Crop Type Accuracy: {ct_acc:.4f} (n={ct_n})\")\n",
        "\n",
        "    print(\"\\n>>>>> EPP Response <<<<<<\")\n",
        "    # EPP metrics (by column letters)\n",
        "    gt_e, gt_e_name = series_by_col_letter(df, \"E\")\n",
        "    pr_o, pr_o_name = series_by_col_letter(df, \"O\")\n",
        "    if gt_e is not None and pr_o is not None:\n",
        "        epp_acc, epp_n = accuracy_from_series(gt_e, pr_o,\n",
        "                                              norm_weed_label, {\"yes\",\"no\",\"n/a\",\"\"})\n",
        "        print(f\"EPP Accuracy (GT {gt_e_name} vs Pred {pr_o_name}): {epp_acc:.4f} (n={epp_n})\")\n",
        "\n",
        "    gt_g, gt_g_name = series_by_col_letter(df, \"G\")\n",
        "    pr_q, pr_q_name = series_by_col_letter(df, \"Q\")\n",
        "    if gt_g is not None and pr_q is not None:\n",
        "        epp_cg_acc, epp_cg_n = accuracy_from_series(gt_g, pr_q,\n",
        "                                                    norm_growth, {\"early\",\"growing\",\"full grown\"})\n",
        "        print(f\"EPP Crop Growth Accuracy (GT {gt_g_name} vs Pred {pr_q_name}): {epp_cg_acc:.4f} (n={epp_cg_n})\")\n",
        "\n",
        "    gt_h, gt_h_name = series_by_col_letter(df, \"H\")\n",
        "    pr_r, pr_r_name = series_by_col_letter(df, \"R\")\n",
        "    if gt_h is not None and pr_r is not None:\n",
        "        epp_ct_acc, epp_ct_n = accuracy_from_series(gt_h, pr_r, norm_crop_type)\n",
        "        print(f\"EPP Crop Type Accuracy (GT {gt_h_name} vs Pred {pr_r_name}): {epp_ct_acc:.4f} (n={epp_ct_n})\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f6e0dea3",
      "metadata": {},
      "source": [
        "# Only GPT as Judge Cases - Evaluation of VLM Responses"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6e92c58c",
      "metadata": {},
      "source": [
        "## GPT Judge"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "80a5aab4",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Resuming: found 0 rows in D:\\Khalifa University 2024\\Conferences - Research\\Al-Ain 2025\\Judge_Temp\\WeedVLM_GPT_41_eval_outputs.csv.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing images: 100%|██████████| 20/20 [03:49<00:00, 11.45s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Done. Wrote results to: D:\\Khalifa University 2024\\Conferences - Research\\Al-Ain 2025\\Judge_Temp\\WeedVLM_GPT_41_eval_outputs.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "import os\n",
        "import csv\n",
        "import time\n",
        "import base64\n",
        "from io import BytesIO\n",
        "from pathlib import Path\n",
        "from typing import List, Tuple, Optional\n",
        "\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "\n",
        "from openai import OpenAI  # pip install --upgrade openai\n",
        "\n",
        "# =========================\n",
        "# 🔐 CONFIG\n",
        "# =========================\n",
        "DOE = \"\" # Add API Key\n",
        "MODEL = \"gpt-4.1\"              # vision-capable model (e.g., \"gpt-4o\")\n",
        "IMAGE_DIR = Path(r\"/Judge_Temp\")\n",
        "OUTPUT_CSV = Path(r\"/Judge_Temp/WeedVLM_GPT_41_eval_outputs.csv\")\n",
        "\n",
        "# Behaviors\n",
        "RESUME = True                 # skip rows already in CSV\n",
        "MAX_RETRIES = 5               # API retry attempts\n",
        "BASE_SLEEP = 2.0              # base seconds for exponential backoff: 2,4,8,16...\n",
        "IMAGE_EXTS = {\".jpg\"}         # you said the images are .jpg (640x640)\n",
        "\n",
        "# =========================\n",
        "# Evaluation Prompt\n",
        "# =========================\n",
        "EVAL_PROMPT = \"\"\"Now Rate the Response on the Following Evaluation Parameters:\n",
        "Grounding: Does the explanation cite concrete, visible evidence (shape/colour/position) tied to specific regions?Score 5 if references are directly checkable in the image; 1 if evidence is generic or absent.\n",
        "Specificity: How precise and unambiguous are the references (grid/row, counts, distances) versus vague words?Score 5 for exact, scannable pointers (“row 2, centre-left, ~0.3 of frame”); 1 for “somewhere left.”\n",
        "Plausibility: Do the stated causes/effects make agronomic and visual sense given the scene? Score 5 when logic follows domain norms; 1 for leaps or contradictory reasoning. \n",
        "Non-Hallucination: Avoids mentioning objects/attributes not present or unverifiable from the image. Score 5 if every claim is image-supported; 1 if there are invented or misidentified elements \n",
        "Actionability: Would the text help a field operator quickly verify or act (where to look, what cue to confirm)?Score 5 if it gives clear next steps/checks; 1 if its not practically useful.\n",
        "\"\"\"\n",
        "\n",
        "# We will wrap the YOLO .txt content into the same user message so the model\n",
        "# can consider detections while scoring.\n",
        "\n",
        "# =========================\n",
        "# Helpers\n",
        "# =========================\n",
        "def encode_image_to_base64_jpeg(image_path: Path) -> str:\n",
        "    \"\"\"\n",
        "    Open image, convert to RGB, re-encode as JPEG, return base64 string.\n",
        "    \"\"\"\n",
        "    with Image.open(image_path) as img:\n",
        "        img = img.convert(\"RGB\")\n",
        "        buf = BytesIO()\n",
        "        img.save(buf, format=\"JPEG\", quality=92)\n",
        "        return base64.b64encode(buf.getvalue()).decode(\"utf-8\")\n",
        "\n",
        "def read_txt_content(txt_path: Path) -> str:\n",
        "    \"\"\"\n",
        "    Read YOLO-format annotations from a .txt file and strip trailing whitespace.\n",
        "    \"\"\"\n",
        "    with open(txt_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        return f.read().strip()\n",
        "\n",
        "def build_user_message_blocks(image_b64: str, yolo_text: str) -> list:\n",
        "    \"\"\"\n",
        "    Construct the Chat Completions 'content' list that includes:\n",
        "      - The evaluation rubric (EVAL_PROMPT)\n",
        "      - The YOLO text content (embedded as plain text)\n",
        "      - The image (data URL)\n",
        "    \"\"\"\n",
        "    # We send the .txt *content* (not the file) in the prompt.\n",
        "    yolo_note = (\n",
        "        \"Context: The following YOLO-format bounding boxes (class 0 = weed) \"\n",
        "        \"are extracted from the paired .txt for this image:\\n\\n\"\n",
        "        f\"{yolo_text}\\n\\n\"\n",
        "        \"Use both the image and these annotations as context for your evaluation.\"\n",
        "    )\n",
        "\n",
        "    return [\n",
        "        {\"type\": \"text\", \"text\": EVAL_PROMPT},\n",
        "        {\"type\": \"text\", \"text\": yolo_note},\n",
        "        {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/jpeg;base64,{image_b64}\"}},\n",
        "    ]\n",
        "\n",
        "def call_openai_vision(client: OpenAI, image_b64: str, yolo_text: str) -> str:\n",
        "    \"\"\"\n",
        "    Single API call using Chat Completions, returning the first message text.\n",
        "    \"\"\"\n",
        "    content_blocks = build_user_message_blocks(image_b64, yolo_text)\n",
        "    resp = client.chat.completions.create(\n",
        "        model=MODEL,\n",
        "        messages=[{\"role\": \"user\", \"content\": content_blocks}],\n",
        "        temperature=0.0,\n",
        "        max_tokens=400,\n",
        "    )\n",
        "    return (resp.choices[0].message.content or \"\").strip()\n",
        "\n",
        "def collect_images(dir_path: Path) -> List[Path]:\n",
        "    return [p for p in sorted(dir_path.iterdir()) if p.suffix.lower() in IMAGE_EXTS and p.is_file()]\n",
        "\n",
        "def find_txt_for_image(img_path: Path) -> Optional[Path]:\n",
        "    \"\"\"\n",
        "    Return the .txt path with the same stem as the image (e.g., a.jpg -> a.txt).\n",
        "    \"\"\"\n",
        "    txt_candidate = img_path.with_suffix(\".txt\")\n",
        "    return txt_candidate if txt_candidate.exists() else None\n",
        "\n",
        "def load_resume_set(csv_path: Path) -> set:\n",
        "    \"\"\"\n",
        "    If RESUME is enabled and CSV exists, collect already-processed image names.\n",
        "    \"\"\"\n",
        "    done = set()\n",
        "    if RESUME and csv_path.exists():\n",
        "        try:\n",
        "            with open(csv_path, \"r\", encoding=\"utf-8\", newline=\"\") as f:\n",
        "                reader = csv.reader(f)\n",
        "                header = next(reader, None)\n",
        "                if header:\n",
        "                    name_idx = 0  # first column is image_name\n",
        "                    for row in reader:\n",
        "                        if row and len(row) > name_idx:\n",
        "                            done.add(row[name_idx])\n",
        "            print(f\"Resuming: found {len(done)} rows in {csv_path}.\")\n",
        "        except Exception as e:\n",
        "            print(f\"Warning: resume failed to read CSV ({e}); starting fresh.\")\n",
        "    return done\n",
        "\n",
        "# =========================\n",
        "# Run Batch\n",
        "# =========================\n",
        "def main():\n",
        "    client = OpenAI(api_key=DOE)\n",
        "\n",
        "    IMAGE_DIR.mkdir(parents=True, exist_ok=True)\n",
        "    images = collect_images(IMAGE_DIR)\n",
        "    if not images:\n",
        "        raise FileNotFoundError(f\"No .jpg images found in: {IMAGE_DIR}\")\n",
        "\n",
        "    # Prepare CSV\n",
        "    new_file = not OUTPUT_CSV.exists()\n",
        "    with open(OUTPUT_CSV, \"a\", encoding=\"utf-8\", newline=\"\") as f:\n",
        "        writer = csv.writer(f)\n",
        "        if new_file:\n",
        "            writer.writerow([\"image_name\", \"gpt_response\"])\n",
        "\n",
        "        # Determine which images to skip if resuming\n",
        "        already = load_resume_set(OUTPUT_CSV) if RESUME else set()\n",
        "\n",
        "        for img_path in tqdm(images, desc=\"Processing images\"):\n",
        "            if img_path.name in already:\n",
        "                continue\n",
        "\n",
        "            txt_path = find_txt_for_image(img_path)\n",
        "            if txt_path is None:\n",
        "                # record an error row and continue\n",
        "                writer.writerow([img_path.name, \"ERROR: missing paired .txt file\"])\n",
        "                f.flush()\n",
        "                continue\n",
        "\n",
        "            # Read data\n",
        "            try:\n",
        "                yolo_text = read_txt_content(txt_path)\n",
        "            except Exception as e:\n",
        "                writer.writerow([img_path.name, f\"ERROR: failed to read .txt: {e}\"])\n",
        "                f.flush()\n",
        "                continue\n",
        "\n",
        "            try:\n",
        "                b64 = encode_image_to_base64_jpeg(img_path)\n",
        "            except Exception as e:\n",
        "                writer.writerow([img_path.name, f\"ERROR: failed to encode image: {e}\"])\n",
        "                f.flush()\n",
        "                continue\n",
        "\n",
        "            # Query with retries\n",
        "            out_text = None\n",
        "            last_err = None\n",
        "            for attempt in range(1, MAX_RETRIES + 1):\n",
        "                try:\n",
        "                    out_text = call_openai_vision(client, b64, yolo_text)\n",
        "                    break\n",
        "                except Exception as e:\n",
        "                    last_err = str(e)\n",
        "                    if attempt == MAX_RETRIES:\n",
        "                        out_text = f\"[ERROR after {MAX_RETRIES} retries] {last_err}\"\n",
        "                        break\n",
        "                    # Exponential backoff\n",
        "                    sleep_s = BASE_SLEEP * (2 ** (attempt - 1))\n",
        "                    time.sleep(sleep_s)\n",
        "\n",
        "            writer.writerow([img_path.name, out_text or \"\"])\n",
        "            f.flush()\n",
        "\n",
        "    print(f\"Done. Wrote results to: {OUTPUT_CSV.resolve()}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ad92f8bc",
      "metadata": {},
      "source": [
        "### Working Code (Cross Checked)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "faa55c21",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[INFO] Excel workbook sheets: ['Gemini_Flash_2.5', 'Gemini_Flash_Lite_2.5', 'LLaMA_4_Maverick', 'LLaMA_4_Scout', 'ChatGPT_4.1', 'ChatGPT_4o']\n",
            "[INFO] Loaded predictions as Excel: Complete_Simple_Data.xlsx | sheet='Gemini_Flash_2.5' with 441 rows, 18 cols\n",
            "[INFO] Loaded prediction mapping for ~441 images from 'Complete_Simple_Data.xlsx'.\n",
            "[INFO] Detected columns: ['#', 'Image Name', 'Weed Detection (GT)', 'Weed Location (GT)', 'Crop Growth (GT)', 'Crop Type (GT)', 'Gemini_Response', 'Weed Detection (Prediction)', 'Weed Location (Prediction)', 'Crop Growth (Prediction)', 'Crop Type (Prediction)', 'Reasoning (Prediction)', 'V2_Weed Detection (Prediction)', 'V2_Weed Location (Prediction)', 'V2_Crop Growth (Prediction)', 'V2_Crop Type (Prediction)', 'V2_Reasoning (Prediction)', 'Weed Detection Penalty (Prompt Entry)']\n",
            "[INFO] Resuming: found 0 rows in D:\\Khalifa University 2024\\Conferences - Research\\Al-Ain 2025\\Judge_Temp\\New_Predictions.csv.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing images:   0%|          | 0/5 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "PROMPT PREVIEW for Weed_Dataset (1).jpg\n",
            "================================================================================\n",
            "=== EVAL_PROMPT ===\n",
            "Now rate the *VLM response* for this image on the following (0–5 each):\n",
            "• Grounding – cites concrete, visible evidence tied to specific regions.\n",
            "• Specificity – precise, scannable references (rows/grid/offsets/counts).\n",
            "• Plausibility – agronomically sensible logic given the scene.\n",
            "• Non-Hallucination – no invented/irrelevant objects or attributes.\n",
            "• Actionability – clear cues/next steps for a field operator.\n",
            "\n",
            "IMPORTANT: The Input Imagee has red rectangles already drawn on the image are the ground truth weed locations. Use them as canonical when judging the VLM response.No Symbols, Nothing Extra, Just Respond in this Manner: Grounding: <Score 0-5>, Specificity: <Score 0-5>, Plausibility: <Score 0-5>, Non-Hallucination: <Score 0-5>, Actionability: <Score 0-5>,\n",
            "\n",
            "=== Cross-check ===\n",
            "Disk image: Weed_Dataset (1).jpg\n",
            "Excel 'Image Name': Weed_Dataset (1)\n",
            "\n",
            "=== Spreadsheet Context ===\n",
            "Spreadsheet Predictions (fallback M columns):\n",
            "- V2_Weed Detection (M): Yes\n",
            "- V2_Weed Location (N): Center-left, within the crop rows where plastic mulch is visible, and along the edges of the dirt path.\n",
            "- V2_Reasoning (Q): Patches of less uniform or slightly lighter green foliage in the center-left area, around the visible plastic mulch, could indicate the presence of weeds competing with the main crop. Additionally, minor green specks along the bare soil pathway could be small weed plants.\n",
            "\n",
            "=== Ground Truth ===\n",
            "Red rectangles drawn on the image = weed locations.\n",
            "\n",
            "=== Image ===\n",
            "Weed_Dataset (1).jpg (base64 bytes not shown)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing images:  20%|██        | 1/5 [00:03<00:13,  3.32s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "PROMPT PREVIEW for Weed_Dataset (2).jpg\n",
            "================================================================================\n",
            "=== EVAL_PROMPT ===\n",
            "Now rate the *VLM response* for this image on the following (0–5 each):\n",
            "• Grounding – cites concrete, visible evidence tied to specific regions.\n",
            "• Specificity – precise, scannable references (rows/grid/offsets/counts).\n",
            "• Plausibility – agronomically sensible logic given the scene.\n",
            "• Non-Hallucination – no invented/irrelevant objects or attributes.\n",
            "• Actionability – clear cues/next steps for a field operator.\n",
            "\n",
            "IMPORTANT: The Input Imagee has red rectangles already drawn on the image are the ground truth weed locations. Use them as canonical when judging the VLM response.No Symbols, Nothing Extra, Just Respond in this Manner: Grounding: <Score 0-5>, Specificity: <Score 0-5>, Plausibility: <Score 0-5>, Non-Hallucination: <Score 0-5>, Actionability: <Score 0-5>,\n",
            "\n",
            "=== Cross-check ===\n",
            "Disk image: Weed_Dataset (2).jpg\n",
            "Excel 'Image Name': Weed_Dataset (2)\n",
            "\n",
            "=== Spreadsheet Context ===\n",
            "Spreadsheet Predictions (primary H columns):\n",
            "- Weed Detection (H): Yes\n",
            "- Weed Location (I): Scattered in the dirt strip between the main crop and the concrete path, particularly along the lower edge of the concrete and interspersed within the drier areas of the dirt strip.\n",
            "- Reasoning (L): The identified plants are growing haphazardly in an uncultivated strip of land next to a concrete structure, showing irregular distribution, varied sizes, and differing levels of health (some green, some dried), distinguishing them from the uniformly planted and dense crop below.\n",
            "\n",
            "=== Ground Truth ===\n",
            "Red rectangles drawn on the image = weed locations.\n",
            "\n",
            "=== Image ===\n",
            "Weed_Dataset (2).jpg (base64 bytes not shown)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing images:  40%|████      | 2/5 [00:06<00:09,  3.09s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "PROMPT PREVIEW for Weed_Dataset (3).jpg\n",
            "================================================================================\n",
            "=== EVAL_PROMPT ===\n",
            "Now rate the *VLM response* for this image on the following (0–5 each):\n",
            "• Grounding – cites concrete, visible evidence tied to specific regions.\n",
            "• Specificity – precise, scannable references (rows/grid/offsets/counts).\n",
            "• Plausibility – agronomically sensible logic given the scene.\n",
            "• Non-Hallucination – no invented/irrelevant objects or attributes.\n",
            "• Actionability – clear cues/next steps for a field operator.\n",
            "\n",
            "IMPORTANT: The Input Imagee has red rectangles already drawn on the image are the ground truth weed locations. Use them as canonical when judging the VLM response.No Symbols, Nothing Extra, Just Respond in this Manner: Grounding: <Score 0-5>, Specificity: <Score 0-5>, Plausibility: <Score 0-5>, Non-Hallucination: <Score 0-5>, Actionability: <Score 0-5>,\n",
            "\n",
            "=== Cross-check ===\n",
            "Disk image: Weed_Dataset (3).jpg\n",
            "Excel 'Image Name': Weed_Dataset (3)\n",
            "\n",
            "=== Spreadsheet Context ===\n",
            "Spreadsheet Predictions (fallback M columns):\n",
            "- V2_Weed Detection (M): Yes\n",
            "- V2_Weed Location (N): Between crop rows, scattered throughout the field where gaps are present.\n",
            "- V2_Reasoning (Q): Assuming weeds are present, they would manifest as smaller, irregularly shaped plants with slightly different leaf structures or shades of green, growing opportunistically in the bare soil patches between the primary crop rows.\n",
            "\n",
            "=== Ground Truth ===\n",
            "Red rectangles drawn on the image = weed locations.\n",
            "\n",
            "=== Image ===\n",
            "Weed_Dataset (3).jpg (base64 bytes not shown)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing images:  60%|██████    | 3/5 [00:12<00:09,  4.59s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "PROMPT PREVIEW for Weed_Dataset (4).jpg\n",
            "================================================================================\n",
            "=== EVAL_PROMPT ===\n",
            "Now rate the *VLM response* for this image on the following (0–5 each):\n",
            "• Grounding – cites concrete, visible evidence tied to specific regions.\n",
            "• Specificity – precise, scannable references (rows/grid/offsets/counts).\n",
            "• Plausibility – agronomically sensible logic given the scene.\n",
            "• Non-Hallucination – no invented/irrelevant objects or attributes.\n",
            "• Actionability – clear cues/next steps for a field operator.\n",
            "\n",
            "IMPORTANT: The Input Imagee has red rectangles already drawn on the image are the ground truth weed locations. Use them as canonical when judging the VLM response.No Symbols, Nothing Extra, Just Respond in this Manner: Grounding: <Score 0-5>, Specificity: <Score 0-5>, Plausibility: <Score 0-5>, Non-Hallucination: <Score 0-5>, Actionability: <Score 0-5>,\n",
            "\n",
            "=== Cross-check ===\n",
            "Disk image: Weed_Dataset (4).jpg\n",
            "Excel 'Image Name': Weed_Dataset (4)\n",
            "\n",
            "=== Spreadsheet Context ===\n",
            "Spreadsheet Predictions (primary H columns):\n",
            "- Weed Detection (H): Yes\n",
            "- Weed Location (I): Along the dirt path on the right side of the image, and in scattered patches within the main crop field, particularly in the left-center and mid-right areas.\n",
            "- Reasoning (L): Distinct plants are visible growing on the uncultivated path. Additionally, irregular patches of lighter green/yellowish vegetation are interspersed within the primary crop canopy, indicating the presence of different plant species or stressed plants that do not match the healthy main crop.\n",
            "\n",
            "=== Ground Truth ===\n",
            "Red rectangles drawn on the image = weed locations.\n",
            "\n",
            "=== Image ===\n",
            "Weed_Dataset (4).jpg (base64 bytes not shown)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing images:  80%|████████  | 4/5 [00:15<00:03,  3.82s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "PROMPT PREVIEW for Weed_Dataset (5).jpg\n",
            "================================================================================\n",
            "=== EVAL_PROMPT ===\n",
            "Now rate the *VLM response* for this image on the following (0–5 each):\n",
            "• Grounding – cites concrete, visible evidence tied to specific regions.\n",
            "• Specificity – precise, scannable references (rows/grid/offsets/counts).\n",
            "• Plausibility – agronomically sensible logic given the scene.\n",
            "• Non-Hallucination – no invented/irrelevant objects or attributes.\n",
            "• Actionability – clear cues/next steps for a field operator.\n",
            "\n",
            "IMPORTANT: The Input Imagee has red rectangles already drawn on the image are the ground truth weed locations. Use them as canonical when judging the VLM response.No Symbols, Nothing Extra, Just Respond in this Manner: Grounding: <Score 0-5>, Specificity: <Score 0-5>, Plausibility: <Score 0-5>, Non-Hallucination: <Score 0-5>, Actionability: <Score 0-5>,\n",
            "\n",
            "=== Cross-check ===\n",
            "Disk image: Weed_Dataset (5).jpg\n",
            "Excel 'Image Name': Weed_Dataset (5)\n",
            "\n",
            "=== Spreadsheet Context ===\n",
            "Spreadsheet Predictions (primary H columns):\n",
            "- Weed Detection (H): Yes\n",
            "- Weed Location (I): Right side of the image, towards the middle-right.\n",
            "- Reasoning (L): A plant with a distinctly different leaf structure (more elongated, possibly palmate) and growth habit (sparser, appears taller) is present on the right, contrasting with the uniform, dense canopy of the main crop which has small, roundish-oval leaves.\n",
            "\n",
            "=== Ground Truth ===\n",
            "Red rectangles drawn on the image = weed locations.\n",
            "\n",
            "=== Image ===\n",
            "Weed_Dataset (5).jpg (base64 bytes not shown)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing images: 100%|██████████| 5/5 [00:18<00:00,  3.76s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Done. Wrote results to: D:\\Khalifa University 2024\\Conferences - Research\\Al-Ain 2025\\Judge_Temp\\New_Predictions.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import re\n",
        "import csv\n",
        "import time\n",
        "import base64\n",
        "from io import BytesIO\n",
        "from pathlib import Path\n",
        "from typing import List, Optional, Dict\n",
        "\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "from openai import OpenAI\n",
        "\n",
        "# =========================\n",
        "# 🔐 CONFIG\n",
        "# =========================\n",
        "DOE = \"\"     # <-- put your real API key here\n",
        "MODEL = \"gpt-4.1\"            # exactly ONE VLM used\n",
        "\n",
        "IMAGE_DIR   = Path(r\"/Judge_Temp\")\n",
        "OUTPUT_CSV  = Path(r\"Judge_Temp/New_Predictions.csv\")\n",
        "\n",
        "EXCEL_PATH  = Path(r\"/Weed-VLM Data Set/Complete_Simple_Data.xlsx\")\n",
        "SHEET_NAME  = \"Gemini_Flash_2.5\"  # pick the exact sheet name\n",
        "\n",
        "RESUME      = True\n",
        "MAX_RETRIES = 5\n",
        "BASE_SLEEP  = 2.0\n",
        "IMAGE_EXTS  = {\".jpg\"}\n",
        "\n",
        "SHOW_PROMPT    = True\n",
        "PROMPT_LOG_DIR = Path(OUTPUT_CSV.parent / \"Prompt_Logs\")\n",
        "\n",
        "# =========================\n",
        "# 📌 Evaluation Prompt\n",
        "# =========================\n",
        "EVAL_PROMPT = (\n",
        "    \"Now rate the *VLM response* for this image on the following (0–5 each):\\n\"\n",
        "    \"• Grounding – cites concrete, visible evidence tied to specific regions.\\n\"\n",
        "    \"• Specificity – precise, scannable references (rows/grid/offsets/counts).\\n\"\n",
        "    \"• Plausibility – agronomically sensible logic given the scene.\\n\"\n",
        "    \"• Non-Hallucination – no invented/irrelevant objects or attributes.\\n\"\n",
        "    \"• Actionability – clear cues/next steps for a field operator.\\n\\n\"\n",
        "    \"IMPORTANT: The Input Imagee has red rectangles already drawn on the image are the ground truth weed locations. \"\n",
        "    \"Use them as canonical when judging the VLM response.\"\n",
        "    \"No Symbols, Nothing Extra, Just Respond in this Manner: Grounding: <Score 0-5>, Specificity: <Score 0-5>, Plausibility: <Score 0-5>, Non-Hallucination: <Score 0-5>, Actionability: <Score 0-5>, \"\n",
        ")\n",
        "\n",
        "# =========================\n",
        "# 🧰 Helpers\n",
        "# =========================\n",
        "def encode_image_to_base64_jpeg(image_path: Path) -> str:\n",
        "    with Image.open(image_path) as img:\n",
        "        img = img.convert(\"RGB\")\n",
        "        buf = BytesIO()\n",
        "        img.save(buf, format=\"JPEG\", quality=92)\n",
        "        return base64.b64encode(buf.getvalue()).decode(\"utf-8\")\n",
        "\n",
        "def _norm(x: object) -> str:\n",
        "    if pd.isna(x): return \"\"\n",
        "    return str(x).strip()\n",
        "\n",
        "def norm_key(s: str) -> str:\n",
        "    \"\"\"\n",
        "    Robust comparable key for filenames:\n",
        "    - lowercase, basename, drop image extension, remove non [a-z0-9]\n",
        "    \"\"\"\n",
        "    s = str(s or \"\").strip().lower().replace(\"\\\\\", \"/\")\n",
        "    s = os.path.basename(s)\n",
        "    if s.endswith((\".jpg\", \".jpeg\", \".png\", \".bmp\", \".webp\", \".tif\", \".tiff\")):\n",
        "        s = Path(s).stem\n",
        "    return re.sub(r\"[^a-z0-9]+\", \"\", s)\n",
        "\n",
        "def is_yes(val: str) -> bool:\n",
        "    v = (_norm(val)).lower()\n",
        "    return v in {\"yes\", \"y\", \"1\", \"true\"}\n",
        "\n",
        "def load_predictions_table(excel_path: Path, sheet_name: str) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Try Excel first; if it fails, try CSV (in case it's a CSV with .xlsx extension).\n",
        "    \"\"\"\n",
        "    try:\n",
        "        xls = pd.ExcelFile(excel_path, engine=\"openpyxl\")\n",
        "        sheets = xls.sheet_names\n",
        "        print(\"[INFO] Excel workbook sheets:\", sheets)\n",
        "        use_sheet = sheet_name if sheet_name in sheets else sheets[0]\n",
        "        if use_sheet != sheet_name:\n",
        "            print(f\"[WARN] Sheet '{sheet_name}' not found. Using '{use_sheet}' instead.\")\n",
        "        df = pd.read_excel(xls, sheet_name=use_sheet, dtype=str)\n",
        "        print(f\"[INFO] Loaded predictions as Excel: {excel_path.name} | sheet='{use_sheet}' with {df.shape[0]} rows, {df.shape[1]} cols\")\n",
        "        return df\n",
        "    except Exception:\n",
        "        # CSV fallback\n",
        "        df = pd.read_csv(excel_path, sep=None, engine=\"python\", dtype=str)\n",
        "        if df.shape[1] == 1:\n",
        "            df2 = pd.read_csv(excel_path, sep=\",\", dtype=str)\n",
        "            if df2.shape[1] > 1:\n",
        "                df = df2\n",
        "        print(f\"[INFO] Loaded predictions as CSV: {excel_path.name} with {df.shape[0]} rows, {df.shape[1]} cols\")\n",
        "        return df\n",
        "\n",
        "def read_spreadsheet_mapping(excel_path: Path, sheet_name: str) -> Dict[str, dict]:\n",
        "    \"\"\"\n",
        "    Build mapping using explicit headers you provided:\n",
        "      H: 'Weed Detection (Prediction)'\n",
        "      I: 'Weed Location (Prediction)'\n",
        "      L: 'Reasoning (Prediction)'\n",
        "      M: 'V2_Weed Detection (Prediction)'\n",
        "      N: 'V2_Weed Location (Prediction)'\n",
        "      Q: 'V2_Reasoning (Prediction)'\n",
        "    We keep both primary & V2 values in the row dict with clear keys.\n",
        "    \"\"\"\n",
        "    df = load_predictions_table(excel_path, sheet_name).applymap(_norm)\n",
        "\n",
        "    required_cols = [\n",
        "        \"Image Name\",\n",
        "        \"Weed Detection (Prediction)\",      # H\n",
        "        \"Weed Location (Prediction)\",       # I\n",
        "        \"Reasoning (Prediction)\",           # L\n",
        "        \"V2_Weed Detection (Prediction)\",   # M\n",
        "        \"V2_Weed Location (Prediction)\",    # N\n",
        "        \"V2_Reasoning (Prediction)\",        # Q\n",
        "    ]\n",
        "    missing = [c for c in required_cols if c not in df.columns]\n",
        "    if missing:\n",
        "        raise KeyError(f\"Missing expected columns in sheet: {missing}\")\n",
        "\n",
        "    # No data-row skipping (header already handled by pandas)\n",
        "    df = df.copy()\n",
        "\n",
        "    mapping: Dict[str, dict] = {}\n",
        "    for _, row in df.iterrows():\n",
        "        excel_img = _norm(row[\"Image Name\"])  # e.g., 'Weed_Dataset (1)'\n",
        "        if not excel_img or excel_img.lower() == \"image name\":  # guard\n",
        "            continue\n",
        "\n",
        "        key = norm_key(excel_img)  # 'weeddataset1'\n",
        "        mapping[key] = {\n",
        "            \"excel_image_name\": excel_img,\n",
        "            \"primary_detect\":  _norm(row[\"Weed Detection (Prediction)\"]),\n",
        "            \"primary_loc\":     _norm(row[\"Weed Location (Prediction)\"]),\n",
        "            \"primary_reason\":  _norm(row[\"Reasoning (Prediction)\"]),\n",
        "            \"v2_detect\":       _norm(row[\"V2_Weed Detection (Prediction)\"]),\n",
        "            \"v2_loc\":          _norm(row[\"V2_Weed Location (Prediction)\"]),\n",
        "            \"v2_reason\":       _norm(row[\"V2_Reasoning (Prediction)\"]),\n",
        "        }\n",
        "\n",
        "    print(f\"[INFO] Loaded prediction mapping for ~{len(mapping)} images from '{excel_path.name}'.\")\n",
        "    print(\"[INFO] Detected columns:\", list(df.columns))\n",
        "    return mapping\n",
        "\n",
        "def build_spreadsheet_context(sp_row: Optional[dict]) -> Optional[str]:\n",
        "    \"\"\"\n",
        "    Branch selection:\n",
        "      - If primary_detect is YES → use primary_loc + primary_reason\n",
        "      - Else if v2_detect is YES → use v2_loc + v2_reason\n",
        "      - Else → None\n",
        "    \"\"\"\n",
        "    if not sp_row:\n",
        "        return None\n",
        "\n",
        "    if is_yes(sp_row.get(\"primary_detect\", \"\")):\n",
        "        loc = _norm(sp_row.get(\"primary_loc\", \"\"))\n",
        "        reas = _norm(sp_row.get(\"primary_reason\", \"\"))\n",
        "        return (\n",
        "            \"Spreadsheet Predictions (primary H columns):\\n\"\n",
        "            f\"- Weed Detection (H): Yes\\n\"\n",
        "            f\"- Weed Location (I): {loc}\\n\"\n",
        "            f\"- Reasoning (L): {reas}\"\n",
        "        )\n",
        "\n",
        "    if is_yes(sp_row.get(\"v2_detect\", \"\")):\n",
        "        loc = _norm(sp_row.get(\"v2_loc\", \"\"))\n",
        "        reas = _norm(sp_row.get(\"v2_reason\", \"\"))\n",
        "        return (\n",
        "            \"Spreadsheet Predictions (fallback M columns):\\n\"\n",
        "            f\"- V2_Weed Detection (M): Yes\\n\"\n",
        "            f\"- V2_Weed Location (N): {loc}\\n\"\n",
        "            f\"- V2_Reasoning (Q): {reas}\"\n",
        "        )\n",
        "\n",
        "    return None\n",
        "\n",
        "def build_user_message_blocks(image_b64: str, spreadsheet_context: Optional[str]) -> list:\n",
        "    blocks = [{\"type\": \"text\", \"text\": EVAL_PROMPT}]\n",
        "    if spreadsheet_context:\n",
        "        blocks.append({\"type\": \"text\", \"text\": spreadsheet_context})\n",
        "    else:\n",
        "        blocks.append({\"type\": \"text\", \"text\": \"[Note] No spreadsheet prediction found for this image; score using GT boxes only.\"})\n",
        "    blocks.append({\"type\": \"text\", \"text\": \"Ground Truth: Red rectangles drawn on the image mark weed locations (canonical).\"})\n",
        "    blocks.append({\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/jpeg;base64,{image_b64}\"}})\n",
        "    return blocks\n",
        "\n",
        "def make_prompt_preview(image_path: Path, excel_image_name: Optional[str], spreadsheet_context: Optional[str]) -> str:\n",
        "    parts = []\n",
        "    parts.append(\"=== EVAL_PROMPT ===\\n\" + EVAL_PROMPT.strip())\n",
        "    parts.append(\"\\n=== Cross-check ===\\n\"\n",
        "                 f\"Disk image: {image_path.name}\\n\"\n",
        "                 f\"Excel 'Image Name': {excel_image_name or '[NO MATCH]'}\")\n",
        "    if spreadsheet_context:\n",
        "        parts.append(\"\\n=== Spreadsheet Context ===\\n\" + spreadsheet_context.strip())\n",
        "    else:\n",
        "        parts.append(\"\\n=== Spreadsheet Context ===\\n[NO MATCH FOUND]\")\n",
        "    parts.append(\"\\n=== Ground Truth ===\\nRed rectangles drawn on the image = weed locations.\")\n",
        "    parts.append(f\"\\n=== Image ===\\n{image_path.name} (base64 bytes not shown)\")\n",
        "    return \"\\n\".join(parts)\n",
        "\n",
        "def call_openai_vision(client: OpenAI, image_b64: str, spreadsheet_context: Optional[str]) -> str:\n",
        "    content_blocks = build_user_message_blocks(image_b64, spreadsheet_context)\n",
        "    resp = client.chat.completions.create(\n",
        "        model=MODEL,\n",
        "        messages=[{\"role\": \"user\", \"content\": content_blocks}],\n",
        "        temperature=0.0,\n",
        "        max_tokens=600,\n",
        "    )\n",
        "    return (resp.choices[0].message.content or \"\").strip()\n",
        "\n",
        "def collect_images(dir_path: Path) -> List[Path]:\n",
        "    return [p for p in sorted(dir_path.iterdir()) if p.suffix.lower() in IMAGE_EXTS and p.is_file()]\n",
        "\n",
        "def load_resume_set(csv_path: Path) -> set:\n",
        "    done = set()\n",
        "    if RESUME and csv_path.exists():\n",
        "        try:\n",
        "            with open(csv_path, \"r\", encoding=\"utf-8\", newline=\"\") as f:\n",
        "                reader = csv.reader(f); next(reader, None)\n",
        "                for row in reader:\n",
        "                    if row: done.add(row[0])\n",
        "            print(f\"[INFO] Resuming: found {len(done)} rows in {csv_path}.\")\n",
        "        except Exception as e:\n",
        "            print(f\"[WARN] resume failed to read CSV ({e}); starting fresh.\")\n",
        "    return done\n",
        "\n",
        "# =========================\n",
        "# 🚀 Run Batch\n",
        "# =========================\n",
        "def main():\n",
        "    client = OpenAI(api_key=DOE)\n",
        "\n",
        "    # Load spreadsheet mapping (explicit headers; no row skip)\n",
        "    sp_map = {}\n",
        "    try:\n",
        "        sp_map = read_spreadsheet_mapping(EXCEL_PATH, SHEET_NAME)\n",
        "    except Exception as e:\n",
        "        print(f\"[WARN] failed to read predictions table ({e}). Proceeding without spreadsheet predictions.\")\n",
        "\n",
        "    IMAGE_DIR.mkdir(parents=True, exist_ok=True)\n",
        "    images = collect_images(IMAGE_DIR)\n",
        "    if not images:\n",
        "        raise FileNotFoundError(f\"No .jpg images found in: {IMAGE_DIR}\")\n",
        "\n",
        "    if SHOW_PROMPT:\n",
        "        PROMPT_LOG_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    new_file = not OUTPUT_CSV.exists()\n",
        "    with open(OUTPUT_CSV, \"a\", encoding=\"utf-8\", newline=\"\") as f:\n",
        "        writer = csv.writer(f)\n",
        "        if new_file:\n",
        "            # includes excel_image_name for cross-check\n",
        "            writer.writerow([\"image_name\", \"excel_image_name\", \"gpt_response\"])\n",
        "\n",
        "        already = load_resume_set(OUTPUT_CSV) if RESUME else set()\n",
        "\n",
        "        for img_path in tqdm(images, desc=\"Processing images\"):\n",
        "            if img_path.name in already:\n",
        "                continue\n",
        "\n",
        "            # Disk key and spreadsheet row\n",
        "            key = norm_key(img_path.name)\n",
        "            sp_row = sp_map.get(key)\n",
        "            excel_img_name = sp_row.get(\"excel_image_name\") if sp_row else None\n",
        "\n",
        "            # Encode image\n",
        "            try:\n",
        "                b64 = encode_image_to_base64_jpeg(img_path)\n",
        "            except Exception as e:\n",
        "                writer.writerow([img_path.name, excel_img_name or \"\", f\"ERROR: failed to encode image: {e}\"])\n",
        "                f.flush()\n",
        "                continue\n",
        "\n",
        "            # Build branch-specific context\n",
        "            spreadsheet_context = build_spreadsheet_context(sp_row)\n",
        "\n",
        "            # Optional: prompt preview (shows which branch was used and exact fields)\n",
        "            if SHOW_PROMPT:\n",
        "                preview = make_prompt_preview(img_path, excel_img_name, spreadsheet_context)\n",
        "                print(\"\\n\" + \"=\"*80)\n",
        "                print(f\"PROMPT PREVIEW for {img_path.name}\")\n",
        "                print(\"=\"*80)\n",
        "                print(preview[:2000])\n",
        "                (PROMPT_LOG_DIR / f\"{img_path.stem}_prompt.txt\").write_text(preview, encoding=\"utf-8\")\n",
        "\n",
        "            # ONE model call per image with retries\n",
        "            out_text, last_err = None, None\n",
        "            for attempt in range(1, MAX_RETRIES + 1):\n",
        "                try:\n",
        "                    out_text = call_openai_vision(client, b64, spreadsheet_context)\n",
        "                    break\n",
        "                except Exception as e:\n",
        "                    last_err = str(e)\n",
        "                    if attempt == MAX_RETRIES:\n",
        "                        out_text = f\"[ERROR after {MAX_RETRIES} retries] {last_err}\"\n",
        "                        break\n",
        "                    time.sleep(BASE_SLEEP * (2 ** (attempt - 1)))\n",
        "\n",
        "            writer.writerow([img_path.name, excel_img_name or \"\", out_text or \"\"])\n",
        "            f.flush()\n",
        "\n",
        "    print(f\"Done. Wrote results to: {OUTPUT_CSV.resolve()}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8fd4b318",
      "metadata": {},
      "source": [
        "## Prompt Simplified Code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "750f825e",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing images: 100%|██████████| 441/441 [22:10<00:00,  3.02s/it]\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import re\n",
        "import csv\n",
        "import time\n",
        "import base64\n",
        "from io import BytesIO\n",
        "from pathlib import Path\n",
        "from typing import List, Optional, Dict\n",
        "\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "from openai import OpenAI\n",
        "\n",
        "# =========================\n",
        "# 🔐 CONFIG\n",
        "# =========================\n",
        "\n",
        "DOE = \"\"     # <-- put your real API key here\n",
        "MODEL = \"gpt-4.1\"            # exactly ONE VLM used\n",
        "\n",
        "IMAGE_DIR   = Path(r\"/Judge_Temp\")\n",
        "OUTPUT_CSV  = Path(r\"Judge_Temp/New_Predictions.csv\")\n",
        "\n",
        "EXCEL_PATH  = Path(r\"/Weed-VLM Data Set/Complete_Simple_Data.xlsx\")\n",
        "SHEET_NAME  = \"Gemini_Flash_2.5\"  # pick the exact sheet name\n",
        "\n",
        "RESUME      = True\n",
        "MAX_RETRIES = 5\n",
        "BASE_SLEEP  = 2.0\n",
        "IMAGE_EXTS  = {\".jpg\"}\n",
        "\n",
        "# Disable all console prints to keep tqdm clean\n",
        "VERBOSE = False\n",
        "\n",
        "# Keep logs of sent prompts? (saved to files only; no printing)\n",
        "SHOW_PROMPT    = False\n",
        "PROMPT_LOG_DIR = Path(OUTPUT_CSV.parent / \"Prompt_Logs\")\n",
        "\n",
        "# =========================\n",
        "# 📌 Evaluation Prompt\n",
        "# =========================\n",
        "EVAL_PROMPT = (\n",
        "    \"Now rate the *VLM response* for this image on the following (0–5 each):\\n\"\n",
        "    \"• Grounding – cites concrete, visible evidence tied to specific regions.\\n\"\n",
        "    \"• Specificity – precise, scannable references (rows/grid/offsets/counts).\\n\"\n",
        "    \"• Plausibility – agronomically sensible logic given the scene.\\n\"\n",
        "    \"• Non-Hallucination – no invented/irrelevant objects or attributes.\\n\"\n",
        "    \"• Actionability – clear cues/next steps for a field operator.\\n\\n\"\n",
        "    \"IMPORTANT: The input image has red rectangles already drawn as the ground-truth weed locations. \"\n",
        "    \"Use them as canonical when judging the VLM response. \"\n",
        "    \"No symbols, nothing extra, No Need to Add Rationale, Never anything Additional, In a Single Line, Always Respond exactly as: Grounding: <0-5>, Specificity: <0-5>, Plausibility: <0-5>, Non-Hallucination: <0-5>, Actionability: <0-5>\"\n",
        ")\n",
        "\n",
        "# =========================\n",
        "# 🧰 Helpers\n",
        "# =========================\n",
        "def encode_image_to_base64_jpeg(image_path: Path) -> str:\n",
        "    with Image.open(image_path) as img:\n",
        "        img = img.convert(\"RGB\")\n",
        "        buf = BytesIO()\n",
        "        img.save(buf, format=\"JPEG\", quality=92)\n",
        "        return base64.b64encode(buf.getvalue()).decode(\"utf-8\")\n",
        "\n",
        "def _norm(x: object) -> str:\n",
        "    if pd.isna(x): return \"\"\n",
        "    return str(x).strip()\n",
        "\n",
        "def norm_key(s: str) -> str:\n",
        "    \"\"\"\n",
        "    Robust comparable key for filenames:\n",
        "    - lowercase, basename, drop image extension, remove non [a-z0-9]\n",
        "    \"\"\"\n",
        "    s = str(s or \"\").strip().lower().replace(\"\\\\\", \"/\")\n",
        "    s = os.path.basename(s)\n",
        "    if s.endswith((\".jpg\", \".jpeg\", \".png\", \".bmp\", \".webp\", \".tif\", \".tiff\")):\n",
        "        s = Path(s).stem\n",
        "    return re.sub(r\"[^a-z0-9]+\", \"\", s)\n",
        "\n",
        "def is_yes(val: str) -> bool:\n",
        "    v = (_norm(val)).lower()\n",
        "    return v in {\"yes\", \"y\", \"1\", \"true\"}\n",
        "\n",
        "def load_predictions_table(excel_path: Path, sheet_name: str) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Try Excel first; if it fails, try CSV (in case it's a CSV with .xlsx extension).\n",
        "    \"\"\"\n",
        "    try:\n",
        "        xls = pd.ExcelFile(excel_path, engine=\"openpyxl\")\n",
        "        use_sheet = sheet_name if sheet_name in xls.sheet_names else xls.sheet_names[0]\n",
        "        df = pd.read_excel(xls, sheet_name=use_sheet, dtype=str)\n",
        "        return df\n",
        "    except Exception:\n",
        "        df = pd.read_csv(excel_path, sep=None, engine=\"python\", dtype=str)\n",
        "        if df.shape[1] == 1:\n",
        "            df2 = pd.read_csv(excel_path, sep=\",\", dtype=str)\n",
        "            if df2.shape[1] > 1:\n",
        "                df = df2\n",
        "        return df\n",
        "\n",
        "def read_spreadsheet_mapping(excel_path: Path, sheet_name: str) -> Dict[str, dict]:\n",
        "    \"\"\"\n",
        "    Build mapping using explicit headers:\n",
        "      H: 'Weed Detection (Prediction)'\n",
        "      I: 'Weed Location (Prediction)'\n",
        "      L: 'Reasoning (Prediction)'\n",
        "      M: 'V2_Weed Detection (Prediction)'\n",
        "      N: 'V2_Weed Location (Prediction)'\n",
        "      Q: 'V2_Reasoning (Prediction)'\n",
        "    \"\"\"\n",
        "    df = load_predictions_table(excel_path, sheet_name).applymap(_norm)\n",
        "\n",
        "    required_cols = [\n",
        "        \"Image Name\",\n",
        "        \"Weed Detection (Prediction)\",      # H\n",
        "        \"Weed Location (Prediction)\",       # I\n",
        "        \"Reasoning (Prediction)\",           # L\n",
        "        \"V2_Weed Detection (Prediction)\",   # M\n",
        "        \"V2_Weed Location (Prediction)\",    # N\n",
        "        \"V2_Reasoning (Prediction)\",        # Q\n",
        "    ]\n",
        "    for c in required_cols:\n",
        "        if c not in df.columns:\n",
        "            raise KeyError(f\"Missing expected column: {c}\")\n",
        "\n",
        "    mapping: Dict[str, dict] = {}\n",
        "    for _, row in df.iterrows():\n",
        "        excel_img = _norm(row[\"Image Name\"])  # e.g., 'Weed_Dataset (1)'\n",
        "        if not excel_img or excel_img.lower() == \"image name\":\n",
        "            continue\n",
        "\n",
        "        key = norm_key(excel_img)  # 'weeddataset1'\n",
        "        mapping[key] = {\n",
        "            \"excel_image_name\": excel_img,\n",
        "            \"primary_detect\":  _norm(row[\"Weed Detection (Prediction)\"]),\n",
        "            \"primary_loc\":     _norm(row[\"Weed Location (Prediction)\"]),\n",
        "            \"primary_reason\":  _norm(row[\"Reasoning (Prediction)\"]),\n",
        "            \"v2_detect\":       _norm(row[\"V2_Weed Detection (Prediction)\"]),\n",
        "            \"v2_loc\":          _norm(row[\"V2_Weed Location (Prediction)\"]),\n",
        "            \"v2_reason\":       _norm(row[\"V2_Reasoning (Prediction)\"]),\n",
        "        }\n",
        "    return mapping\n",
        "\n",
        "def build_spreadsheet_context(sp_row: Optional[dict]) -> Optional[str]:\n",
        "    \"\"\"\n",
        "    Branch selection:\n",
        "      - If primary_detect is YES → use primary_loc + primary_reason\n",
        "      - Else if v2_detect is YES → use v2_loc + v2_reason\n",
        "      - Else → None\n",
        "    \"\"\"\n",
        "    if not sp_row:\n",
        "        return None\n",
        "\n",
        "    if is_yes(sp_row.get(\"primary_detect\", \"\")):\n",
        "        loc = _norm(sp_row.get(\"primary_loc\", \"\"))\n",
        "        reas = _norm(sp_row.get(\"primary_reason\", \"\"))\n",
        "        return (\n",
        "            \"Spreadsheet Predictions (primary H columns):\\n\"\n",
        "            f\"- Weed Detection (H): Yes\\n\"\n",
        "            f\"- Weed Location (I): {loc}\\n\"\n",
        "            f\"- Reasoning (L): {reas}\"\n",
        "        )\n",
        "\n",
        "    if is_yes(sp_row.get(\"v2_detect\", \"\")):\n",
        "        loc = _norm(sp_row.get(\"v2_loc\", \"\"))\n",
        "        reas = _norm(sp_row.get(\"v2_reason\", \"\"))\n",
        "        return (\n",
        "            \"Spreadsheet Predictions (fallback M columns):\\n\"\n",
        "            f\"- V2_Weed Detection (M): Yes\\n\"\n",
        "            f\"- V2_Weed Location (N): {loc}\\n\"\n",
        "            f\"- V2_Reasoning (Q): {reas}\"\n",
        "        )\n",
        "\n",
        "    return None\n",
        "\n",
        "def build_user_message_blocks(image_b64: str, spreadsheet_context: Optional[str]) -> list:\n",
        "    blocks = [{\"type\": \"text\", \"text\": EVAL_PROMPT}]\n",
        "    if spreadsheet_context:\n",
        "        blocks.append({\"type\": \"text\", \"text\": spreadsheet_context})\n",
        "    else:\n",
        "        blocks.append({\"type\": \"text\", \"text\": \"[Note] No spreadsheet prediction found for this image; score using GT boxes only.\"})\n",
        "    blocks.append({\"type\": \"text\", \"text\": \"Ground Truth: Red rectangles drawn on the image mark weed locations (canonical).\"})\n",
        "    blocks.append({\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/jpeg;base64,{image_b64}\"}})\n",
        "    return blocks\n",
        "\n",
        "def call_openai_vision(client: OpenAI, image_b64: str, spreadsheet_context: Optional[str]) -> str:\n",
        "    content_blocks = build_user_message_blocks(image_b64, spreadsheet_context)\n",
        "    resp = client.chat.completions.create(\n",
        "        model=MODEL,\n",
        "        messages=[{\"role\": \"user\", \"content\": content_blocks}],\n",
        "        temperature=0.0,\n",
        "        max_tokens=600,\n",
        "    )\n",
        "    return (resp.choices[0].message.content or \"\").strip()\n",
        "\n",
        "def collect_images(dir_path: Path) -> List[Path]:\n",
        "    return [p for p in sorted(dir_path.iterdir()) if p.suffix.lower() in IMAGE_EXTS and p.is_file()]\n",
        "\n",
        "def load_resume_set(csv_path: Path) -> set:\n",
        "    done = set()\n",
        "    if RESUME and csv_path.exists():\n",
        "        try:\n",
        "            with open(csv_path, \"r\", encoding=\"utf-8\", newline=\"\") as f:\n",
        "                reader = csv.reader(f); next(reader, None)\n",
        "                for row in reader:\n",
        "                    if row: done.add(row[0])\n",
        "        except Exception:\n",
        "            pass\n",
        "    return done\n",
        "\n",
        "# =========================\n",
        "# 🚀 Run Batch\n",
        "# =========================\n",
        "def main():\n",
        "    client = OpenAI(api_key=DOE)\n",
        "\n",
        "    # Load spreadsheet mapping (explicit headers; no row skip)\n",
        "    try:\n",
        "        sp_map = read_spreadsheet_mapping(EXCEL_PATH, SHEET_NAME)\n",
        "    except Exception:\n",
        "        sp_map = {}\n",
        "\n",
        "    IMAGE_DIR.mkdir(parents=True, exist_ok=True)\n",
        "    images = collect_images(IMAGE_DIR)\n",
        "    if not images:\n",
        "        raise FileNotFoundError(f\"No .jpg images found in: {IMAGE_DIR}\")\n",
        "\n",
        "    if SHOW_PROMPT:\n",
        "        PROMPT_LOG_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    new_file = not OUTPUT_CSV.exists()\n",
        "    with open(OUTPUT_CSV, \"a\", encoding=\"utf-8\", newline=\"\") as f:\n",
        "        writer = csv.writer(f)\n",
        "        if new_file:\n",
        "            # ✅ Added 4th column: spreadsheet_context\n",
        "            writer.writerow([\"image_name\", \"excel_image_name\", \"gpt_response\", \"spreadsheet_context\"])\n",
        "\n",
        "        already = load_resume_set(OUTPUT_CSV) if RESUME else set()\n",
        "\n",
        "        for img_path in tqdm(images, desc=\"Processing images\"):\n",
        "            if img_path.name in already:\n",
        "                continue\n",
        "\n",
        "            key = norm_key(img_path.name)\n",
        "            sp_row = sp_map.get(key)\n",
        "            excel_img_name = sp_row.get(\"excel_image_name\") if sp_row else \"\"\n",
        "\n",
        "            try:\n",
        "                b64 = encode_image_to_base64_jpeg(img_path)\n",
        "            except Exception as e:\n",
        "                writer.writerow([img_path.name, excel_img_name, f\"ERROR: failed to encode image: {e}\", \"\"])\n",
        "                f.flush()\n",
        "                continue\n",
        "\n",
        "            spreadsheet_context = build_spreadsheet_context(sp_row)\n",
        "\n",
        "            # (Optional) Save prompt preview to file only (no prints)\n",
        "            if SHOW_PROMPT:\n",
        "                preview = (\n",
        "                    \"=== EVAL_PROMPT ===\\n\" + EVAL_PROMPT.strip() +\n",
        "                    \"\\n\\n=== Cross-check ===\\n\"\n",
        "                    f\"Disk image: {img_path.name}\\n\"\n",
        "                    f\"Excel 'Image Name': {excel_img_name or '[NO MATCH]'}\\n\" +\n",
        "                    (\"\\n=== Spreadsheet Context ===\\n\" + spreadsheet_context if spreadsheet_context else\n",
        "                     \"\\n=== Spreadsheet Context ===\\n[NO MATCH FOUND]\") +\n",
        "                    \"\\n\\n=== Ground Truth ===\\nRed rectangles drawn on the image = weed locations.\" +\n",
        "                    f\"\\n\\n=== Image ===\\n{img_path.name} (base64 bytes not shown)\"\n",
        "                )\n",
        "                (PROMPT_LOG_DIR / f\"{img_path.stem}_prompt.txt\").write_text(preview, encoding=\"utf-8\")\n",
        "\n",
        "            # ONE model call per image with retries\n",
        "            out_text = None\n",
        "            last_err = None\n",
        "            for attempt in range(1, MAX_RETRIES + 1):\n",
        "                try:\n",
        "                    out_text = call_openai_vision(client, b64, spreadsheet_context)\n",
        "                    break\n",
        "                except Exception as e:\n",
        "                    last_err = str(e)\n",
        "                    if attempt == MAX_RETRIES:\n",
        "                        out_text = f\"[ERROR after {MAX_RETRIES} retries] {last_err}\"\n",
        "                        break\n",
        "                    time.sleep(BASE_SLEEP * (2 ** (attempt - 1)))\n",
        "\n",
        "            # ✅ Write the spreadsheet_context into the CSV as the 4th column\n",
        "            writer.writerow([img_path.name, excel_img_name, out_text or \"\", spreadsheet_context or \"\"])\n",
        "            f.flush()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "vlm",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
