{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e4ace6d",
   "metadata": {},
   "source": [
    "# Zero‚Äëshot Weed Detection with OpenAI VLMs (Batch Runner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e6c8a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import base64\n",
    "import csv\n",
    "import time\n",
    "from io import BytesIO\n",
    "from pathlib import Path\n",
    "\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "import openai  # pip install --upgrade openai\n",
    "\n",
    "# =========================\n",
    "# üîê CONFIG\n",
    "# =========================\n",
    "openai.api_key = \"sk-proj-\"\n",
    "\n",
    "# Vision-capable model (use what you have access to)\n",
    "MODEL = \"gpt-4o\"  # or \"gpt-4.1\"\n",
    "\n",
    "# Folder containing your images (441 images)\n",
    "IMAGE_DIR = Path(\"/Joint_Val\")\n",
    "\n",
    "# Output CSV with exactly two columns: image_name, gpt_response\n",
    "OUTPUT_CSV = Path(\"/WeedVLM_GPT_4o_outputs.csv\")\n",
    "\n",
    "# Optional: resume if CSV exists (skip already-processed files)\n",
    "RESUME = True\n",
    "\n",
    "# Retry/backoff\n",
    "MAX_RETRIES = 5\n",
    "BASE_SLEEP = 2.0  # seconds\n",
    "\n",
    "# Allowed image extensions\n",
    "IMAGE_EXTS = {\".jpg\", \".jpeg\", \".png\", \".bmp\", \".webp\", \".tif\", \".tiff\"}\n",
    "\n",
    "# =========================\n",
    "# üìå Prompt (exactly as provided)\n",
    "# =========================\n",
    "PROMPT = (\n",
    "    \"Analyze the image and provide output in exactly this format, and nothing extra:\\n\"\n",
    "    \"Weed Detection: <Yes or No>\\n\"\n",
    "    \"Weed Location: <Mention Position in the Image>\\n\"\n",
    "    \"Reasoning: <Explain Reasoning>\\n\"\n",
    "    \"Crop Growth: <Early, Growing or Full Grown>\\n\"\n",
    "    \"Crop Type: <Predict Crop Type>\\n\"\n",
    "    \"If your main response is 'No Weed', then rewrite the response again with V2_ at the start of each field, assuming weed is present\\n\"\n",
    ")\n",
    "\n",
    "# =========================\n",
    "# üß∞ Helpers\n",
    "# =========================\n",
    "def encode_image_to_base64_jpeg(image_path: Path) -> str:\n",
    "    \"\"\"\n",
    "    Open the image (any format), convert to RGB, re-encode as JPEG,\n",
    "    return base64 string suitable for 'data:image/jpeg;base64,...'\n",
    "    \"\"\"\n",
    "    with Image.open(image_path) as img:\n",
    "        img = img.convert(\"RGB\")\n",
    "        buf = BytesIO()\n",
    "        img.save(buf, format=\"JPEG\", quality=92)\n",
    "        return base64.b64encode(buf.getvalue()).decode(\"utf-8\")\n",
    "\n",
    "\n",
    "def query_openai_vision(image_b64: str, prompt: str) -> str:\n",
    "    \"\"\"\n",
    "    Uses the Chat Completions API in the same structure as your working reference:\n",
    "    - model: vision-capable (e.g., gpt-4.1, gpt-4o)\n",
    "    - messages content with text + image_url (data URL)\n",
    "    Returns the plain text content from the first choice.\n",
    "    \"\"\"\n",
    "    resp = openai.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\"type\": \"text\", \"text\": prompt},\n",
    "                    {\n",
    "                        \"type\": \"image_url\",\n",
    "                        \"image_url\": {\"url\": f\"data:image/jpeg;base64,{image_b64}\"},\n",
    "                    },\n",
    "                ],\n",
    "            }\n",
    "        ],\n",
    "        max_tokens=350,\n",
    "        temperature=0.0,\n",
    "    )\n",
    "    return resp.choices[0].message.content.strip()\n",
    "\n",
    "\n",
    "# =========================\n",
    "# üöÄ Run Batch\n",
    "# =========================\n",
    "def main():\n",
    "    IMAGE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "    images = [p for p in sorted(IMAGE_DIR.iterdir()) if p.suffix.lower() in IMAGE_EXTS]\n",
    "    if not images:\n",
    "        raise FileNotFoundError(f\"No images found in: {IMAGE_DIR}\")\n",
    "\n",
    "    # Resume support\n",
    "    seen = set()\n",
    "    if RESUME and OUTPUT_CSV.exists():\n",
    "        try:\n",
    "            with open(OUTPUT_CSV, \"r\", encoding=\"utf-8\", newline=\"\") as f:\n",
    "                reader = csv.reader(f)\n",
    "                header = next(reader, None)\n",
    "                if header and len(header) >= 2:\n",
    "                    idx_name = 0  # first column is image_name\n",
    "                    for row in reader:\n",
    "                        if row and len(row) >= 1:\n",
    "                            seen.add(row[idx_name])\n",
    "            print(f\"Resuming: found {len(seen)} rows already in {OUTPUT_CSV}.\")\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    # Open CSV and write header if new\n",
    "    write_header = not OUTPUT_CSV.exists()\n",
    "    with open(OUTPUT_CSV, \"a\", encoding=\"utf-8\", newline=\"\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        if write_header:\n",
    "            writer.writerow([\"image_name\", \"gpt_response\"])\n",
    "\n",
    "        for img_path in tqdm(images, desc=\"Processing images\"):\n",
    "            if img_path.name in seen:\n",
    "                continue\n",
    "\n",
    "            # Encode image\n",
    "            try:\n",
    "                b64 = encode_image_to_base64_jpeg(img_path)\n",
    "            except Exception as e:\n",
    "                writer.writerow([img_path.name, f\"ERROR: failed to encode image: {e}\"])\n",
    "                f.flush()\n",
    "                continue\n",
    "\n",
    "            # Query with retries\n",
    "            out_text = None\n",
    "            for attempt in range(1, MAX_RETRIES + 1):\n",
    "                try:\n",
    "                    out_text = query_openai_vision(b64, PROMPT)\n",
    "                    break\n",
    "                except Exception as e:\n",
    "                    err_msg = str(e)\n",
    "                    if attempt == MAX_RETRIES:\n",
    "                        out_text = f\"[ERROR after {MAX_RETRIES} retries] {err_msg}\"\n",
    "                        break\n",
    "                    sleep_s = BASE_SLEEP * (2 ** (attempt - 1))\n",
    "                    time.sleep(sleep_s)\n",
    "\n",
    "            # Write exactly two columns\n",
    "            writer.writerow([img_path.name, out_text if out_text is not None else \"\"])\n",
    "            f.flush()\n",
    "\n",
    "    print(f\"Done. Wrote results to: {OUTPUT_CSV.resolve()}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vlm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
